{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "P9sEZKtzI7LM"
   },
   "outputs": [],
   "source": [
    "X_train = [\"This was really awesome an awesome movie\",\n",
    "           \"Great movie! Ilikes it a lot\",\n",
    "           \"Happy Ending! Awesome Acting by hero\",\n",
    "           \"loved it!\",\n",
    "           \"Bad not upto the mark\",\n",
    "           \"Could have been better\",\n",
    "           \"really Dissapointed by the movie\"]\n",
    "# X_test = \"it was really awesome and really disspntd\"\n",
    "\n",
    "y_train = [\"positive\",\"positive\",\"positive\",\"positive\",\"negative\",\"negative\",\"negative\"] # 1- Positive class, 0- negative class\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eho36_66O3Qp",
    "outputId": "8aceb1a8-4714-4691-8235-8894d49fb54d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['This was awesome an awesome movie',\n",
       " 'Great movie! Ilikes it a lot',\n",
       " 'Happy Ending! Awesome Acting by hero',\n",
       " 'loved it!',\n",
       " 'Bad not upto the mark',\n",
       " 'Could have been better',\n",
       " 'Dissapointed by the movie']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train # Reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lfiyn79qO-0T"
   },
   "source": [
    "# Cleaning of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DzXC8UmGPL1I"
   },
   "outputs": [],
   "source": [
    "# Tokenize\n",
    "# \"I am a python dev\" -> [\"I\", \"am\", \"a\", \"python\", \"dev\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UZJ2jyJXO5RB"
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize import RegexpTokenizer\n",
    "# NLTK -> Tokenize -> RegexpTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zPcXkoKCQfRe"
   },
   "outputs": [],
   "source": [
    "# Stemming\n",
    "# \"Playing\" -> \"Play\"\n",
    "# \"Working\" -> \"Work\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "te5tMTiOQ4AH"
   },
   "outputs": [],
   "source": [
    "from nltk.stem.porter import PorterStemmer\n",
    "# NLTK -> Stem -> Porter -> PorterStemmer\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "# NLTK -> Corpus -> stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Lj9GnzQ-Rgfs",
    "outputId": "e370ec92-0773-4c39-d4b8-3630096eefd1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Downloading the stopwords\n",
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BYBAAa5URpn4"
   },
   "outputs": [],
   "source": [
    "tokenizer = RegexpTokenizer(r\"\\w+\")\n",
    "en_stopwords = set(stopwords.words('english'))\n",
    "ps = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EteN13pXSXdA"
   },
   "outputs": [],
   "source": [
    "def getCleanedText(text):\n",
    "  text = text.lower()\n",
    "\n",
    "  # tokenizing\n",
    "  tokens = tokenizer.tokenize(text)\n",
    "  new_tokens = [token for token in tokens if token not in en_stopwords]\n",
    "  stemmed_tokens = [ps.stem(tokens) for tokens in new_tokens]\n",
    "  clean_text = \" \".join(stemmed_tokens)\n",
    "  return clean_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kZKnlgY1U2tM"
   },
   "source": [
    "# Input from the user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DVpCNF6oU8lz"
   },
   "outputs": [],
   "source": [
    "X_test = [\"it was bad\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SLlJ6ykQVMs0"
   },
   "outputs": [],
   "source": [
    "X_clean = [getCleanedText(i) for i in X_train]\n",
    "xt_clean = [getCleanedText(i) for i in X_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4ucLQoXkVeIc",
    "outputId": "5af7746d-6507-4e62-9370-6544ab1c8ef5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['awesom awesom movi',\n",
       " 'great movi ilik lot',\n",
       " 'happi end awesom act hero',\n",
       " 'love',\n",
       " 'bad upto mark',\n",
       " 'could better',\n",
       " 'dissapoint movi']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 88
    },
    "id": "Q8ZKuifkVhG0",
    "outputId": "a547cff3-ec8f-4a4c-8c35-a1c48f7d300b"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'\\nX_train = [\"This was awesome an awesome movie\",\\n           \"Great movie! Ilikes it a lot\",\\n           \"Happy Ending! Awesome Acting by hero\",\\n           \"loved it!\",\\n           \"Bad not upto the mark\",\\n           \"Could have been better\",\\n           \"Dissapointed by the movie\"]\\n'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data before cleaning\n",
    "'''\n",
    "X_train = [\"This was awesome an awesome movie\",\n",
    "           \"Great movie! Ilikes it a lot\",\n",
    "           \"Happy Ending! Awesome Acting by hero\",\n",
    "           \"loved it!\",\n",
    "           \"Bad not upto the mark\",\n",
    "           \"Could have been better\",\n",
    "           \"Dissapointed by the movie\"]\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nvk17ZJOWCHM"
   },
   "source": [
    "# Vectorize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "knd_2aoFWEia"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ac_4Z59zWhdI"
   },
   "outputs": [],
   "source": [
    "cv = CountVectorizer(ngram_range = (1,2))\n",
    "# \"I am PyDev\" -> \"i am\", \"am Pydev\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ni5j2x5eXB53"
   },
   "outputs": [],
   "source": [
    "X_vec = cv.fit_transform(X_clean).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "q593wLzUXNbY",
    "outputId": "428d23a2-6da2-4adf-feae-2cf672a91382"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 2, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 1, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1,\n",
       "        1, 0, 0, 1, 1, 0, 0],\n",
       "       [1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 1, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 1, 0, 0, 1, 1],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 1, 0, 0, 0]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NafJdQnKXPJS",
    "outputId": "fe2ef59a-7544-450c-b005-a5674363704f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['act', 'act hero', 'awesom', 'awesom act', 'awesom awesom', 'awesom movi', 'bad', 'bad upto', 'better', 'could', 'could better', 'dissapoint', 'dissapoint movi', 'end', 'end awesom', 'great', 'great movi', 'happi', 'happi end', 'hero', 'ilik', 'ilik lot', 'lot', 'love', 'mark', 'movi', 'movi ilik', 'upto', 'upto mark']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "print(cv.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pzA-qA03XWXW"
   },
   "outputs": [],
   "source": [
    "Xt_vect = cv.transform(xt_clean).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JmiEl_O8XnTI",
    "outputId": "1c2ee2a3-5323-440c-e4b4-1d9254c8ae0f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xt_vect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gb5m850iX762"
   },
   "source": [
    "# Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JZRkPXl2YB3R"
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dUDUIe58YZ8P"
   },
   "outputs": [],
   "source": [
    "mn = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zSKclpTVYdNn",
    "outputId": "e62e67b1-19c1-482c-8a17-955c479f3b4b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mn.fit(X_vec, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ke13CUKKYm18"
   },
   "outputs": [],
   "source": [
    "y_pred = mn.predict(Xt_vect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-BBlq2ejYx_o",
    "outputId": "a1a7a40a-4b3e-4813-d3d5-f151060ec309"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['negative'], dtype='<U8')"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fGyAmlw4Y22k"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XBodg43rYv7V"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Dp3nQLGCXxl8"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cIF05wihXi8I"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KZy54yroUxRi"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yzHL48nqSfn7"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
